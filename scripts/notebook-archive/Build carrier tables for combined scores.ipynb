{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build carrier tables for MAVEs scored by a combination of Dan's calibrations and VEP methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports and constants\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from cvfgaou import hailtools, gctools, notation\n",
    "from cvfgaou.notation import GEQ_CHAR, LEQ_CHAR\n",
    "\n",
    "BUCKET = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "\n",
    "SPLICE_AI_FILTER_MAX = 0.2\n",
    "AF_FILTER_MAX = 0.01 # We don't filter for rare variants in functional data, but we do for VEPs\n",
    "CALIBRATION_VERSION = '2025-07-10'\n",
    "DATAFRAME_VERSION = '17036510'\n",
    "POINTS_DIR = f'{BUCKET}/calibration-points_2025-09-10'\n",
    "RESULTS_DIR = f'{BUCKET}/combined_classes_2025-09-10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genes of interest\n",
    "genes = [\n",
    "    'APP',\n",
    "    'BAP1',\n",
    "    'BARD1',\n",
    "    'BRCA1',\n",
    "    'BRCA2',\n",
    "    'BRIP1',\n",
    "    'CALM1',\n",
    "    'CALM2',\n",
    "    'CALM3',\n",
    "    'GCK',\n",
    "    'KCNH2',\n",
    "    'KCNQ4',\n",
    "    'MSH2',\n",
    "    'OTC',\n",
    "    'PALB2',\n",
    "    'PRKN',\n",
    "    'PTEN',\n",
    "    'RAD51C',\n",
    "    'RAD51D',\n",
    "    'SCN5A',\n",
    "    'SNCA',\n",
    "    'TARDBP',\n",
    "    'TP53',\n",
    "    #'VWF'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "hl.init()\n",
    "wgs_mt_path = os.getenv(\"WGS_EXOME_SPLIT_HAIL_PATH\")\n",
    "wgs_mt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wgs\n",
    "wgs_mt = hl.read_matrix_table(wgs_mt_path)\n",
    "wgs_mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls $WORKSPACE_BUCKET/cvfg_17036510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CVFG dataframe\n",
    "cvfg_df = pd.read_csv(\n",
    "    f'{BUCKET}/cvfg_17036510/final_pillar_data_with_clinvar_gnomad_wREVEL_wAM_wspliceAI_expanded_090425.csv.gz',\n",
    "    #index_col=0, ID is non-unique in the expanded table\n",
    "    dtype={\n",
    "        'Dataset': str,\n",
    "        'Gene': str,\n",
    "        'Chrom': str,\n",
    "        #'hg38_start': int,\n",
    "        #'hg38_end': int,\n",
    "        'ref_allele': str,\n",
    "        'alt_allele': str,\n",
    "        #'auth_reported_score': float,\n",
    "        'auth_reported_func_class': str\n",
    "    }\n",
    ")\n",
    "cvfg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(cvfg_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe:\n",
    "\n",
    "working_df = cvfg_df[\n",
    "    # cvfg_df.Gene.isin(genes) & # Limit to our genes\n",
    "    (cvfg_df.Flag != '*') & # Drop flagged variants (mapping errors etc.)\n",
    "    ( # Splice variant filtering:\n",
    "        (cvfg_df.splice_measure == 'Yes') | # Keep all variants from splice-detecting assays\n",
    "        ( # Filter the rest on SpliceAI thresholds\n",
    "            (cvfg_df.spliceAI_DS_AG <= SPLICE_AI_FILTER_MAX) &\n",
    "            (cvfg_df.spliceAI_DS_AL <= SPLICE_AI_FILTER_MAX) &\n",
    "            (cvfg_df.spliceAI_DS_DG <= SPLICE_AI_FILTER_MAX) &\n",
    "            (cvfg_df.spliceAI_DS_DL <= SPLICE_AI_FILTER_MAX)\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvfgaou.notation import GEQ_CHAR, LEQ_CHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evidence threshold mapping from integer points to labels\n",
    "evidence_strength_series = pd.Series({\n",
    "    nsign * points: f'{inequality} {sign}{points}'\n",
    "    for nsign, sign, inequality in ((1, '+', GEQ_CHAR), (-1, '-', LEQ_CHAR))\n",
    "    for points in (8,4,3,2,1)\n",
    "}).sort_index(ascending=False)\n",
    "#evidence_strength_series = pd.Series({\n",
    "#    +8: \"Pathogenic very strong\",\n",
    "#    +4: \"Pathogenic strong\",\n",
    "#    +2: \"Pathogenic moderate\",\n",
    "#    +1: \"Pathogenic supporting\",\n",
    "#    -1: \"Benign supporting\",\n",
    "#    -2: \"Benign moderate\",\n",
    "#    -4: \"Benign strong\",\n",
    "#    -8: \"Benign very strong\"\n",
    "#})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign calibration points to each variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to build a table of the form\n",
    "# contig, pos, ref, alt, points, func/vep, data source, calibration method\n",
    "\n",
    "for blob in tqdm(gctools.list_blobs(\n",
    "    f'{BUCKET}/calibrations/assays_{CALIBRATION_VERSION}/',\n",
    "    return_uris=False\n",
    ")):\n",
    "    if blob.path.endswith('.json'):\n",
    "        calibration = json.loads(blob.download_as_text())\n",
    "        \n",
    "        dataset = calibration['scoreset_name']\n",
    "\n",
    "        dataset_df = working_df[working_df['Dataset'] == dataset]\n",
    "        \n",
    "        if dataset_df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Check how thresholds are provided. If lists, assume they should be aligned to 1, 2, 3, 4, 8\n",
    "        pathogenic_thresholds = calibration['final_pathogenic_thresholds']\n",
    "        if isinstance(pathogenic_thresholds, list):\n",
    "            print(f'Warning: pathogenic thresholds provided as a list for {dataset}')\n",
    "            pathogenic_thresholds = dict(zip([1,2,3,4,8], pathogenic_thresholds))\n",
    "        \n",
    "        benign_thresholds = calibration['final_benign_thresholds']\n",
    "        if isinstance(benign_thresholds, list):\n",
    "            print(f'Warning: benign thresholds provided as a list for {dataset}')\n",
    "            benign_thresholds = dict(zip([-1,-2,-3,-4,-8], benign_thresholds))\n",
    "        \n",
    "        # Build series of thesholds\n",
    "        thresholds = pd.concat(\n",
    "            [\n",
    "                pd.Series(pathogenic_thresholds),\n",
    "                pd.Series(benign_thresholds)\n",
    "            ]\n",
    "        )\n",
    "        thresholds.index = pd.to_numeric(thresholds.index)\n",
    "        thresholds.sort_index(inplace=True)\n",
    "        \n",
    "        # Can't work without thresholds\n",
    "        if thresholds.isna().all():\n",
    "            continue\n",
    "        \n",
    "        # Directionality of thresholds\n",
    "        increasing = calibration.get('inverted') == 'inverted'\n",
    "        \n",
    "        # Check that threholds are increasing(decreasing):\n",
    "        if increasing:\n",
    "            assert thresholds.dropna().is_monotonic_increasing, f'Thresholds for {dataset} are expected to be increasing: {thresholds}'\n",
    "            comparisons = [pd.Series.le] * 5 + [pd.Series.ge] * 5\n",
    "        else:\n",
    "            assert thresholds.dropna().is_monotonic_decreasing, f'Thresholds for {dataset} are expected to be decreasing: {thresholds}'\n",
    "            comparisons = [pd.Series.ge] * 5 + [pd.Series.le] * 5\n",
    "        comparisons_series = pd.Series(comparisons, [-8,-4,-3,-2,-1,1,2,3,4,8])\n",
    "        \n",
    "        # Align thresholds, labels, and comparisons\n",
    "        thresholds_df = pd.concat(\n",
    "            {\n",
    "                'Threshold': thresholds,\n",
    "                'Comparison': comparisons_series\n",
    "            },\n",
    "            axis='columns'\n",
    "        ).dropna(how='any').sort_index(key=lambda idx: idx.to_series().abs())\n",
    "        \n",
    "        result_dfs = []\n",
    "        \n",
    "        for gene, gene_df in dataset_df.groupby('Gene'):\n",
    "            \n",
    "            result_df = gene_df[\n",
    "                ['Chrom', 'hg38_start', 'ref_allele', 'alt_allele']\n",
    "            ].rename(columns={\n",
    "                'Chrom': 'contig',\n",
    "                'hg38_start': 'pos',\n",
    "                'ref_allele': 'ref',\n",
    "                'alt_allele': 'alt'\n",
    "            })\n",
    "            \n",
    "            result_df['points'] = 0\n",
    "            \n",
    "            for points, threshold, compare in tqdm(thresholds_df.itertuples(index=True)):\n",
    "                \n",
    "                result_df.loc[\n",
    "                    compare(gene_df['auth_reported_score'].astype(float), threshold),\n",
    "                    'points'\n",
    "                ] = points\n",
    "            \n",
    "            result_df['evidence'] = 'functional'\n",
    "            result_df['dataset'] = dataset\n",
    "            result_df['calibration'] = CALIBRATION_VERSION\n",
    "            result_df['gene'] = gene\n",
    "            \n",
    "            result_dfs.append(result_df)\n",
    "        \n",
    "        if result_dfs:\n",
    "            pd.concat(result_dfs, ignore_index=True).to_parquet(f'{POINTS_DIR}/{dataset}_{CALIBRATION_VERSION}.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VEP calibrations: these will run on a simplified list of variants for each gene\n",
    "\n",
    "vep_scores_df = working_df[\n",
    "    (working_df.gnomad_MAF <= AF_FILTER_MAX) & # VEPs get filtered by AF\n",
    "    # VEPS always get filtered by SpliceAI\n",
    "    (working_df.spliceAI_DS_AG <= SPLICE_AI_FILTER_MAX) & \n",
    "    (working_df.spliceAI_DS_AL <= SPLICE_AI_FILTER_MAX) &\n",
    "    (working_df.spliceAI_DS_DG <= SPLICE_AI_FILTER_MAX) &\n",
    "    (working_df.spliceAI_DS_DL <= SPLICE_AI_FILTER_MAX) &\n",
    "    # We can't score variants without AA position\n",
    "    ~working_df.aa_pos.isna()\n",
    "][[\n",
    "    'Gene',\n",
    "    'Chrom', 'hg38_start', 'ref_allele', 'alt_allele',\n",
    "    'aa_ref', 'aa_pos', 'aa_alt', 'REVEL', 'AM_score'\n",
    "]]\n",
    "\n",
    "vep_scores_df['hg38_start'] = pd.to_numeric(vep_scores_df['hg38_start'], downcast='integer')\n",
    "vep_scores_df['aa_pos'] = pd.to_numeric(vep_scores_df['aa_pos'], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mutpred table and filter it down to the genes of interest\n",
    "mutpred_df = pd.concat(\n",
    "    [\n",
    "        df[df['gene_symbol'].isin(genes)]\n",
    "        for df in tqdm(pd.read_table(f'{BUCKET}/mutpred2/IGVFFI7749UFOK.tsv.gz', chunksize=100000))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vep_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutpred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vep_scores_df = vep_scores_df.assign(\n",
    "    aa_sub=lambda df: df.apply(lambda s:f'{s.aa_ref}{s.aa_pos:d}{s.aa_alt}', axis='columns')\n",
    ").merge(\n",
    "    mutpred_df['gene_symbol', 'Substitution', 'MutPred2 score'],\n",
    "    left_on=['Gene', 'aa_sub'],\n",
    "    right_on=['gene_symbol', 'Substitution'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vep_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect calibration methods\n",
    "#############################\n",
    "\n",
    "## Load gene-specific Calibration tables\n",
    "\n",
    "# This table is indexed by gene\n",
    "gene_thresholds_dfs = {\n",
    "    method_long: pd.read_csv(\n",
    "        f'{BUCKET}/calibrations/pillarg_{method_short}_gene_specific_thresh.csv',\n",
    "        index_col=0\n",
    "    )\n",
    "    for method_long, method_short in (\n",
    "        ('AlphaMissense', 'AM'),\n",
    "        ('MutPred2', 'MP2'),\n",
    "        ('REVEL', 'REVEL')\n",
    "    )\n",
    "}\n",
    "\n",
    "# Mapping from our thresholds to thresholds used in the table and the respective comparison direction\n",
    "gs_threshold_map = {\n",
    "    (+points if sign == '+' else -points): (f'{criterion}_{strength.title()}', comparator)\n",
    "    for _, sign, criterion, _, comparator, _ in notation.DOE_TABLE\n",
    "    for points, strength in notation.SOE_TABLE\n",
    "}\n",
    "\n",
    "## Global calibrations\n",
    "\n",
    "# Thresholds from Bergquist et al. 10.1016/j.gim.2025.101402\n",
    "global_thresholds = {\n",
    "    'REVEL': {\n",
    "        +4: lambda s: s >= 0.932, # Pathogenic strong\n",
    "        +3: lambda s: s >= 0.879, # -- modetate+\n",
    "        +2: lambda s: s >= 0.773, # -- moderate\n",
    "        +1: lambda s: s >= 0.644, # Pathogenic supporting\n",
    "        -1: lambda s: s <= 0.290, # Benign supporting\n",
    "        -2: lambda s: s <= 0.183, # -- moderate\n",
    "        -3: lambda s: s <= 0.052, # -- moderate+\n",
    "        -4: lambda s: s <= 0.016  # -- strong\n",
    "    },\n",
    "    'MutPred2': {\n",
    "        -4: lambda s: s <= 0.010, # Benign Strong\n",
    "        -3: lambda s: s <= 0.031, # Benign Moderate+\n",
    "        -2: lambda s: s <= 0.197, # Benign Moderate\n",
    "        -1: lambda s: s <= 0.391, # Benign Supporting\n",
    "        +1: lambda s: s >= 0.737, # Pathogenic Supporting\n",
    "        +2: lambda s: s >= 0.829, # Pathogenic Moderate\n",
    "        +3: lambda s: s >= 0.895, # Pathogenic Moderate+\n",
    "        +4: lambda s: s >= 0.932  # Pathogenic Strong\n",
    "    },\n",
    "    'AlphaMissense': {\n",
    "        -3: lambda s: s <= 0.070, # Benign Moderate+: <= 0.070\n",
    "        -2: lambda s: s <= 0.099, # Benign Moderate: <= 0.099\n",
    "        -1: lambda s: s <= 0.169, # Benign Supporting: <= 0.169\n",
    "        +1: lambda s: s >= 0.792, # Pathogenic Supporting: >= 0.792\n",
    "        +2: lambda s: s >= 0.906, # Pathogenic Moderate: >= 0.906\n",
    "        +3: lambda s: s >= 0.972, # Pathogenic Moderate+: >= 0.972\n",
    "        +4: lambda s: s >= 0.990  # Pathogenic Strong: >= 0.990\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score variants\n",
    "################\n",
    "\n",
    "predictor_cols = {\n",
    "    'AlphaMissense': 'AM_score',\n",
    "    'MutPred2': 'MutPred2 score',\n",
    "    'REVEL': 'REVEL'\n",
    "}\n",
    "\n",
    "result_dfs = []\n",
    "\n",
    "# Using the global method\n",
    "for predictor, threshold_map in tqdm(global_thresholds.items()):\n",
    "    threshold_series = pd.Series(threshold_map).sort_index(key=lambda idx: idx.to_series().abs())\n",
    "\n",
    "    result_df = vep_scores_df[\n",
    "        ['Gene', 'Chrom', 'hg38_start', 'ref_allele', 'alt_allele']\n",
    "    ].renam(columns={\n",
    "        'Gene': 'gene',\n",
    "        'Chrom': 'contig',\n",
    "        'hg38_start': 'pos',\n",
    "        'ref_allele': 'ref',\n",
    "        'alt_allele': 'alt'\n",
    "    })\n",
    "    \n",
    "    result_df['points'] = 0\n",
    "\n",
    "    for points, compare in theshold_series.items():\n",
    "        result_df.loc[\n",
    "            compare(vep_scores_df[predictor_cols[predictor]])\n",
    "            'points'\n",
    "        ] = points \n",
    "        \n",
    "    result_df['evidence'] = 'predictor'\n",
    "    result_df['dataset'] = predictor\n",
    "    result_df['calibration'] = 'Bergquist et al. 10.1016/j.gim.2025.101402'\n",
    "    result_dfs.append(result_df)\n",
    "\n",
    "\n",
    "gs_threshold_map_series = pd.Series(gs_threshold_map).sort_index(key=lambda idx: idx.to_series().abs())\n",
    "\n",
    "# Gene-specific method\n",
    "for gene, gene_df in tqdm(vep_scores_df.groupby('Gene')):\n",
    "    for predictor, gene_thresholds_df in gene_thresholds_dfs:\n",
    "        if gene in gene_thesholds_df.index:\n",
    "            \n",
    "            result_df = gene_df[\n",
    "                ['Chrom', 'hg38_start', 'ref_allele', 'alt_allele']\n",
    "            ].rename(columns={\n",
    "                'Chrom': 'contig',\n",
    "                'hg38_start': 'pos',\n",
    "                'ref_allele': 'ref',\n",
    "                'alt_allele': 'alt'\n",
    "            })\n",
    "            \n",
    "            result_df['points'] = 0\n",
    "            \n",
    "            for points, (label, comparator) in gs_thresholds_map.items():\n",
    "                threshold = gene_thresholds_df.at[gene, label]\n",
    "                if not np.isnan(threshold):\n",
    "                    result_df.loc[\n",
    "                        comparator(gene_df[predictor_cols[predictor]], threshold),\n",
    "                        'points'\n",
    "                    ] = points\n",
    "                    \n",
    "            result_df['gene'] = gene\n",
    "            result_df['evidence'] = 'predictor'\n",
    "            result_df['dataset'] = predictor\n",
    "            result_df['calibration'] = 'gene-specific'\n",
    "            \n",
    "            result_dfs.append(result_df)\n",
    "\n",
    "pd.concat(result_dfs, ignore_index=True).to_parquet(f'{POINTS_DIR}/predictors.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum best scores\n",
    "\n",
    "all_scores = pd.concat(\n",
    "    (pd.read_parquet(f) for f in gctools.list_blobs(POINTS_DIR)),\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = (\n",
    "    all_scores\n",
    "    .group_by(['gene', 'contig', 'pos', 'ref', 'alt', 'evidence'])['points'].sort_values(key=pd.Series.abs).first()\n",
    "    .group_by(['gene', 'contig', 'pos', 'ref', 'alt'])['points'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer points ranges\n",
    "point_groups = {\n",
    "    f'{GEQ_CHAR if points > 0 else LEQ_CHAR} {points:+d}':\n",
    "        ((lambda x: x >= points) if points > 0 else (lambda x: x <= points))\n",
    "    for points in best_scores.points.drop_duplicates()\n",
    "    if points != 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_bins_df = pd.read_csv(f'{BUCKET}/clinvar/clinvar-bins.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposures_file = f'{RESULTS_DIR}/exposures/combined.parquet'\n",
    "clinvar_file = f'{RESULTS_DIR}/clinvar_maps/combined.parquet'\n",
    "af_file = f'{RESULTS_DIR}/af_maps/combined.parquet'\n",
    "\n",
    "clinvar_classes_dfs = []\n",
    "join_af_map = {}\n",
    "gene_result_dfs = []\n",
    "\n",
    "for gene, gene_df in tqdm(best_scores.groupby('gene')):\n",
    "    for classification, compare in point_groups:\n",
    "                \n",
    "        variant_df = gene_df[\n",
    "            ['contig', 'pos', 'ref', 'alt']\n",
    "        ][\n",
    "            compare(gene_df.points)\n",
    "        ].dropna(how='any').assign(Chromosome = lambda df: 'chr'+df['contig']).astype({'pos': int})\n",
    "\n",
    "        if variant_df.empty:\n",
    "            continue\n",
    "\n",
    "        exposure_df, af_map, clinvar_df = hailtools.get_exposure_package(\n",
    "            variant_df,\n",
    "            wgs_mt,\n",
    "            clinvar_bins_df,\n",
    "            contig_col='Chromosome',\n",
    "            pos_col='pos',\n",
    "            ref_col='ref',\n",
    "            alt_col='alt',\n",
    "            metadata_dict={\n",
    "                'Dataset': 'Combined points',\n",
    "                'Gene': gene,\n",
    "                'Classifier': f'Combined points',\n",
    "                'Classification': classification,\n",
    "                'Data Version': DATAFRAME_VERSION\n",
    "            }\n",
    "        )\n",
    "\n",
    "        clinvar_classes_dfs.append(clinvar_df)\n",
    "        joint_af_map.update(af_map)\n",
    "        gene_result_dfs.append(exposure_df)\n",
    "\n",
    "if clinvar_classes_dfs:\n",
    "    pd.concat(clinvar_classes_dfs, ignore_index=True).to_parquet(clinvar_file)\n",
    "if joint_af_map:\n",
    "    pd.Series(joint_af_map).to_frame(name='AF').to_parquet(af_file)\n",
    "if gene_result_dfs:\n",
    "    pd.concat(gene_result_dfs, ignore_index=True).to_parquet(exposures_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
