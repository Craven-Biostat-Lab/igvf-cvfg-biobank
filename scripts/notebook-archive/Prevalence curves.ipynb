{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaplan-meier survival curves\n",
    "\n",
    "### Action items\n",
    "This notebooks is a WIP. The following tasks are outstanding:\n",
    "\n",
    "- [ ] Debug curve workflow\n",
    "- [ ] Extend to all genes of interest\n",
    "- [ ] Move code to common functions\n",
    "- [ ] Move common functions to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports and constants\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from cvfgaou import aou, survival, gctools, data\n",
    "\n",
    "DATASET = os.environ[\"WORKSPACE_CDR\"]\n",
    "BUCKET = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "DATA_DIR = f'{BUCKET}/data_v2'\n",
    "CURVES_VERSION = '2025-10-19'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gene case pools definitions\n",
    "# Taking them from the gene phenotypes defined for the project\n",
    "\n",
    "cohorts = aou.CohortLoader(\n",
    "    gene_cohort_map = {\n",
    "        gene: (\n",
    "            {f'{p} case pool.tsv.gz' for p in case_phenos},\n",
    "            {f'{p} control pool.tsv.gz' for p in control_phenos}\n",
    "        )\n",
    "        for gene, (case_phenos, control_phenos, _) in data.gene_phenotypes.items()\n",
    "    },\n",
    "    ancestry_df = pd.read_table(f'{DATA_DIR}/ancestry_pca.tsv.gz', index_col='research_id'),\n",
    "    demo_df = pd.read_table(f'{DATA_DIR}/demo.tsv.gz', index_col='person_id'),\n",
    "    data_dir = DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get event count statistics\n",
    "\n",
    "count_events_sql = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT\n",
    "            person_id,\n",
    "            COUNT(DISTINCT condition_start_date) AS n_events,\n",
    "            MIN(condition_start_date) AS first_event,\n",
    "            MAX(condition_start_date) AS last_event\n",
    "        FROM `{DATASET}.condition_occurrence`\n",
    "        WHERE\n",
    "            person_id IN (\n",
    "                SELECT person_id FROM `{DATASET}.cb_search_person`\n",
    "                WHERE has_whole_genome_variant = 1\n",
    "            )\n",
    "        GROUP BY person_id\n",
    "    ) INNER JOIN (\n",
    "        SELECT\n",
    "            person_id,\n",
    "            sex_at_birth,\n",
    "            dob,\n",
    "            age_at_cdr\n",
    "        FROM `{DATASET}.cb_search_person`\n",
    "    ) USING (person_id)\n",
    "\"\"\"\n",
    "\n",
    "count_events_df = pd.read_gbq(\n",
    "    count_events_sql,\n",
    "    index_col='person_id',\n",
    "    dialect='standard',\n",
    "    use_bqstorage_api=('BIGQUERY_STORAGE_API_ENABLED' in os.environ),\n",
    "    progress_bar_type='tqdm_notebook'\n",
    ").assign(\n",
    "    first_event = lambda df: pd.to_datetime(df.first_event),\n",
    "    last_event = lambda df: pd.to_datetime(df.last_event),\n",
    "    dob = lambda df: pd.to_datetime(df.dob)\n",
    ")\n",
    "\n",
    "count_events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute age at last event for all cohorts\n",
    "\n",
    "age_at_last_event = (count_events_df.last_event - count_events_df.dob).dt.days / 365.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get combined dataframes: Take earliest event time for each person (separately for conditions and surveys)\n",
    "cohort_dfs = {\n",
    "    gene:\n",
    "        pd.concat(\n",
    "            pd.concat(\n",
    "                (\n",
    "                    pd.read_table(f'{DATA_DIR}/{cohort}')\n",
    "                    for cohort in cohort_group\n",
    "                ),\n",
    "                ignore_index=True\n",
    "            ).groupby('person_id').min(numeric_only=True).assign(case=case_label)\n",
    "            for case_label, cohort_group in zip((True, False), cohorts)\n",
    "        ).join(\n",
    "            age_at_last_event.rename('age_at_last_event'),\n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "    for gene, cohorts in tqdm(cohorts.gene_cohort_map.items())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare timepoints for survival curves\n",
    "\n",
    "def get_cohort_timepoints(cohort_df, use_survey_times):\n",
    "    \n",
    "    cohort_df = cohort_df.copy()\n",
    "    \n",
    "    if use_survey_times and cohort_df.columns.isin({'survey_high_age', 'survey_low_age'}).any():\n",
    "        \n",
    "        cohort_df['survey_upper_limit'] = cohort_df[['survey_high_age', 'age_at_last_event']].min(axis='columns')\n",
    "        cohort_df['survey_lower_limit'] = cohort_df[['survey_low_age', 'age_at_last_event']].min(axis='columns')\n",
    "        cohort_df['survey_midpoint'] = cohort_df[['survey_upper_limit', 'survey_lower_limit']].mean(axis='columns')\n",
    "\n",
    "    else:\n",
    "        cohort_df['survey_midpoint'] = None\n",
    "\n",
    "    return cohort_df.assign(\n",
    "        timepoints=cohort_df.age_at_last_event.mask( # Use last event time for controls\n",
    "            cohort_df.case, # For cases:\n",
    "            cohort_df.condition_onset_age.mask( # Use condition onset\n",
    "                cohort_df.condition_onset_age.isna(), # except where there is no condition onset, then\n",
    "                cohort_df.survey_midpoint # Use survey midpoint\n",
    "            )\n",
    "        )\n",
    "    ).dropna(axis='index', subset='timepoints').astype({'timepoints': float})\n",
    "\n",
    "\n",
    "# Censor timepoints for AoU compliance\n",
    "\n",
    "def censor_timepoints(cohort_with_timepoints, left=20, right=20):\n",
    "    \"\"\" Censor 'left' earliest timepoints and 'right' latest timepoints\n",
    "    \n",
    "    The way this censoring is done is that the 'left' ('right') earliest (latest) timepoints\n",
    "    are re-assigned the largest (smallest) value in the set.\n",
    "    \"\"\"\n",
    "    \n",
    "    left_group = cohort_with_timepoints.nsmallest(left, 'timepoints').index\n",
    "    left_time = cohort_with_timepoints.loc[left_group, 'timepoints'].max()\n",
    "    \n",
    "    right_group = cohort_with_timepoints.nlargest(right, 'timepoints').index\n",
    "    right_time = cohort_with_timepoints.loc[right_group, 'timepoints'].min()\n",
    "    \n",
    "    result = cohort_with_timepoints.copy()\n",
    "    result.loc[left_group, 'timepoints'] = left_time\n",
    "    result.loc[right_group, 'timepoints'] = right_time\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curve generation\n",
    "\n",
    "For each gene we want to have\n",
    " - The full cohort curve\n",
    " - A curve for every classification\n",
    " \n",
    "When presenting, we will group plots by dataset and include the full cohort curve in every group.\n",
    "\n",
    "For processing the data, we want to first load all exposure tables into one big dataframe, and then iterate over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls classes_2025-10-16/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls $WORKSPACE_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p classes_2025-10-16\n",
    "!gsutil -m cp -r $WORKSPACE_BUCKET/classes_2025-09-09/* classes_2025-10-16/\n",
    "!gsutil -m cp -r $WORKSPACE_BUCKET/classes_2025-10-15/* classes_2025-10-16/\n",
    "!gsutil -m cp -r $WORKSPACE_BUCKET/combined_classes_2025-10-17/* classes_2025-10-16/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all exposure tables into our dataframe\n",
    "\n",
    "exposures_df = pd.concat(\n",
    "    (\n",
    "        df\n",
    "        for f in tqdm(Path('classes_2025-10-16/exposures').iterdir())\n",
    "        for gene, df in pd.read_parquet(f).reset_index().groupby('Gene')\n",
    "        if gene in cohorts.gene_cohort_map\n",
    "        if 'person_id' in df.columns # Need to fix missing person_ids in some exposure tables\n",
    "    ),\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_sets = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene, gene_df in tqdm(exposures_df.groupby('Gene')):\n",
    "    # Iterate over genes first to get gene-wide tables\n",
    "    cohort_df = cohort_dfs[gene]\n",
    "    \n",
    "    for survey in (True, False):\n",
    "        # Deprecate survey timepoints altogether\n",
    "        if survey:\n",
    "            continue\n",
    "        # If surveys exist, also produce curves with surveys\n",
    "        if survey and not cohort_df.columns.str.startswith('survey_').any():\n",
    "            continue\n",
    "        \n",
    "        # Full population curve\n",
    "        curve_sets[(gene, survey, 'N/A', 'Baseline', 'Full cohort')] = survival.get_kaplan_meier_estimate(\n",
    "            censor_timepoints(get_cohort_timepoints(cohort_df, survey))\n",
    "        )\n",
    "        \n",
    "        # !Future TODO!\n",
    "        # Curve without variants\n",
    "        #curve_sets[(gene, survey, 'N/A', 'Baseline', 'No variants')] = survival.get_kaplan_meier_estimate(\n",
    "        #    censor_timepoints(get_cohort_timepoints(cohort_df, survey))\n",
    "        #)\n",
    "        \n",
    "        for (dataset, classifier, classification), class_df in gene_df.groupby(['Dataset', 'Classifier', 'Classification']):\n",
    "            timepoints_df = censor_timepoints(get_cohort_timepoints(\n",
    "                cohort_df[cohort_df.index.isin(pd.to_numeric(class_df.person_id, downcast='integer'))],\n",
    "                survey\n",
    "            ))\n",
    "\n",
    "            if not timepoints_df.empty:\n",
    "                curve_sets[(\n",
    "                    gene, survey, dataset, classifier, classification\n",
    "                )] = survival.get_kaplan_meier_estimate(timepoints_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into one big frame\n",
    "curves_df = pd.concat(\n",
    "    curve_sets,\n",
    "    names = ['Gene', 'Using surveys', 'Dataset', 'Classifier', 'Classification']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save estimated\n",
    "\n",
    "curves_df.to_parquet(f'{BUCKET}/survival-estimates/survival-estimates_{CURVES_VERSION}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError('Stop here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls -lh $WORKSPACE_BUCKET/survival-estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_df.person_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curves_df.reset_index().Classification.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "\n",
    "for gene, plot_df in curves_df.groupby(['Gene', 'Dataset']):\n",
    "    \n",
    "    plot_df.reset_index(inplace=True)\n",
    "    \n",
    "    n_facets = plot_df['Classifier'].nunique()\n",
    "    \n",
    "    plot = (\n",
    "        p9.ggplot(\n",
    "            data=plot_df.reset_index(),\n",
    "            mapping=p9.aes(\n",
    "                x='Age',\n",
    "                y='Survival to onset',\n",
    "                ymin='Survival_LI',\n",
    "                ymax='Survival_UI',\n",
    "                color='Classification',\n",
    "                fill='Classification'\n",
    "            )\n",
    "        )\n",
    "        + p9.geom_ribbon(alpha=0.3, color='none')\n",
    "        + p9.geom_line()\n",
    "        + p9.facet_wrap('~ Gene + Dataset + Classifier', ncol=1)\n",
    "        + p9.theme(\n",
    "            figure_size=(6, 4*n_facets)\n",
    "        )\n",
    "    )\n",
    "    display(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "\n",
    "plot = (\n",
    "    p9.ggplot(\n",
    "        data=plot_df,\n",
    "        mapping=p9.aes(\n",
    "            x='Age',\n",
    "            y='Survival to onset',\n",
    "            ymin='Survival_LI',\n",
    "            ymax='Survival_UI'\n",
    "        )\n",
    "    )\n",
    "    + p9.geom_ribbon(alpha=0.3)\n",
    "    + p9.geom_line()\n",
    ")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls $WORKSPACE_BUCKET/prelim_exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load exposures of interest\n",
    "\n",
    "brca1_clinvar_df = pd.read_csv(f'{BUCKET}/prelim_exposures/clinvar_vat_BRCA1.csv')\n",
    "brca1_clinvar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brca1_clinvar_df.Classification.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kaplan_meier_estimate(cohort_with_timepoints_df):\n",
    "    \n",
    "    # Censor last 20 timepoints\n",
    "    to_drop = cohort_with_timepoints_df.nlargest(20, 'timepoints').index\n",
    "    cohort_with_timepoints_df = cohort_with_timepoints_df.drop(to_drop)\n",
    "\n",
    "    time, prob_survival, conf_int = kaplan_meier_estimator(\n",
    "        event=cohort_with_timepoints_df.case,\n",
    "        time_exit=cohort_with_timepoints_df.timepoints,\n",
    "        conf_type='log-log'\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            'Age': time,\n",
    "            'Survival to onset': prob_survival,\n",
    "            'Survival_LI': conf_int[0],\n",
    "            'Survival_UI': conf_int[1]\n",
    "        }\n",
    "    )\n",
    "\n",
    "combined_df = pd.concat(\n",
    "    {\n",
    "        classification: get_kaplan_meier_estimate(cohort_subset)\n",
    "        for classification in brca1_clinvar_df.Classification.drop_duplicates()\n",
    "        for cohort_subset in (\n",
    "            brca_cohort_with_timepoints_df[\n",
    "                brca_cohort_with_timepoints_df.index.isin(\n",
    "                    brca1_clinvar_df.person_id[brca1_clinvar_df.Classification == classification]\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "        if not cohort_subset.empty\n",
    "    },\n",
    "    names = ['Classification']\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, df in combined_df[combined_df.Classification.str.endswith('Pathogenic')].groupby('Classification'):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_plot_df = pd.concat(\n",
    "    [combined_df, plot_df.assign(Classification='Full cohort')],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = (\n",
    "    p9.ggplot(\n",
    "        data=big_plot_df,\n",
    "        mapping=p9.aes(\n",
    "            x='Age',\n",
    "            y='Survival to onset',\n",
    "            ymin='Survival_LI',\n",
    "            ymax='Survival_UI',\n",
    "            color='Classification',\n",
    "            fill='Classification'\n",
    "        )\n",
    "    )\n",
    "    + p9.geom_ribbon(alpha=0.3, color='none')\n",
    "    + p9.geom_line()\n",
    ")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls $WORKSPACE_BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls $WORKSPACE_BUCKET/aux_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brca1_vat = pd.read_table(f'{BUCKET}/aux_data/brca1_vat.tsv')\n",
    "brca1_vat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brca1_vat.assign(\n",
    "    pathogenic = brca1_vat.clinvar_classification.str.contains('pathogenic')\n",
    ").groupby(['contig', 'position']).pathogenic.any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Error('Stop here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvfg_df = pd.read_csv(\n",
    "    df_path,\n",
    "    index_col='ID',\n",
    "    usecols=[\n",
    "        'ID', 'Dataset', 'Gene', 'Chrom', 'STRAND', 'ref_allele', 'alt_allele',\n",
    "        'auth_reported_score', 'auth_reported_func_class',\n",
    "        'gnomad_MAF',\n",
    "        'clinvar_sig', 'clinvar_star'\n",
    "    ],\n",
    "    dtype={\n",
    "        #'HGNC_id': str,\n",
    "        'Chrom': str,\n",
    "        'STRAND': str,\n",
    "        #'auth_reported_score': float, # Contains some strings, will want to resolve in the future\n",
    "        'auth_reported_func_class': str\n",
    "        #'hg38_start': int,\n",
    "        #'hg38_end': int\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvfg_df[cvfg_df.Gene.str.contains('BRCA')][['Gene', 'Dataset', 'auth_reported_func_class']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvfg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{BUCKET}/prelim_exposures/clinvar_BRCA1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
