{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build carrier tables for MAVEs scored by a combination of Dan's calibrations and VEP methods.\n",
    "\n",
    "Calculation of combined points provided by Malvika Tejura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports and constants\n",
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from cvfgaou import hailtools, gctools, notation, data\n",
    "from cvfgaou.notation import GEQ_CHAR, LEQ_CHAR\n",
    "\n",
    "BUCKET = os.environ[\"WORKSPACE_BUCKET\"]\n",
    "\n",
    "DATAFRAME_VERSION = '17796333' # For bookkeeping\n",
    "RESULTS_DIR = f'{BUCKET}/combined_classes_2025-12-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load points dataframe\n",
    "\n",
    "points_df = pd.read_csv(f'{BUCKET}/precomputed/Dan_fxn_calibrations_new_2025_2018_clust_calib_121425.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "hl.init()\n",
    "wgs_mt_path = os.getenv(\"WGS_EXOME_SPLIT_HAIL_PATH\")\n",
    "wgs_mt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wgs\n",
    "wgs_mt = hl.read_matrix_table(wgs_mt_path)\n",
    "wgs_mt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to our genes\n",
    "working_df = points_df[points_df['Gene'].isin(data.gene_phenotypes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix for CALM genes\n",
    "genes = {\n",
    "    g\n",
    "    for g in working_df.Gene.drop_duplicates()\n",
    "    if g != 'CALM1_2_3'\n",
    "} | {'CALM1', 'CALM2', 'CALM3'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvfgaou.notation import GEQ_CHAR, LEQ_CHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evidence threshold mapping from integer points to labels\n",
    "evidence_strength_series = pd.Series({\n",
    "    nsign * points: f'{inequality} {sign}{points}'\n",
    "    for nsign, sign, inequality in ((1, '+', GEQ_CHAR), (-1, '-', LEQ_CHAR))\n",
    "    for points in (8,4,3,2,1)\n",
    "}).sort_index(ascending=False)\n",
    "#evidence_strength_series = pd.Series({\n",
    "#    +8: \"Pathogenic very strong\",\n",
    "#    +4: \"Pathogenic strong\",\n",
    "#    +2: \"Pathogenic moderate\",\n",
    "#    +1: \"Pathogenic supporting\",\n",
    "#    -1: \"Benign supporting\",\n",
    "#    -2: \"Benign moderate\",\n",
    "#    -4: \"Benign strong\",\n",
    "#    -8: \"Benign very strong\"\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer points ranges\n",
    "\n",
    "point_groups = {\n",
    "    '0' if points == 0 else f'{GEQ_CHAR if points > 0 else LEQ_CHAR} {points:+d}':\n",
    "        (pd.Series.eq, points) if points == 0 else (\n",
    "            (pd.Series.ge, points) if points > 0 else (pd.Series.le, points)\n",
    "        )\n",
    "#        ((lambda x: dummy_geq(x, points)) if points > 0 else (lambda x: dummy_leq(x, points)))\n",
    "#        ((lambda x: x >= points) if points > 0 else (lambda x: x <= points))\n",
    "    for points in range(-16, 17)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinvar_bins_df = pd.read_csv(f'{BUCKET}/clinvar/clinvar-bins.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gene_df = working_df[working_df.Gene == 'BRCA2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifier = 'total_points_dan_18_25_YP_REVEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_points_df = test_gene_df.groupby(\n",
    "    ['Chrom', 'hg38_start', 'ref_allele', 'alt_allele']\n",
    ")[test_classifier].apply(\n",
    "    lambda s: s.iloc[s.abs().argmax()]\n",
    ").to_frame(name='points').reset_index().astype({\n",
    "    'Chrom': str,\n",
    "    'hg38_start': int,\n",
    "    'ref_allele': str,\n",
    "    'alt_allele': str,\n",
    "    'points': float\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene, gene_df in tqdm(working_df.groupby('Gene')):\n",
    "\n",
    "    exposures_file = f'{RESULTS_DIR}/exposures/combined_{gene}.parquet'\n",
    "    clinvar_file = f'{RESULTS_DIR}/clinvar_maps/combined_{gene}.parquet'\n",
    "    af_file = f'{RESULTS_DIR}/af_maps/combined_{gene}.parquet'\n",
    "    \n",
    "    if all((gctools.blob_exists(f) for f in (exposures_file, clinvar_file, af_file))):\n",
    "        print(f'Files for {gene} exist, skipping.')\n",
    "        continue\n",
    "\n",
    "    clinvar_classes_dfs = []\n",
    "    joint_af_map = {}\n",
    "    gene_result_dfs = []\n",
    "    \n",
    "    # In case we run the same analysis for different points columns. Those become our classifiers.\n",
    "    for classifier in ['total_points_dan_18_25_best_predictor']:\n",
    "        points_df = gene_df.groupby(\n",
    "            ['Chrom', 'hg38_start', 'ref_allele', 'alt_allele']\n",
    "        )[classifier].apply(\n",
    "            lambda s: s.iloc[s.abs().argmax()]\n",
    "        ).to_frame(name='points').reset_index().astype({\n",
    "            'Chrom': str,\n",
    "            'hg38_start': int,\n",
    "            'ref_allele': str,\n",
    "            'alt_allele': str,\n",
    "            'points': float\n",
    "        }).assign(Chromosome = lambda df: 'chr' + df[\"Chrom\"])\n",
    "\n",
    "        for classification, (compare, threshold) in point_groups.items():\n",
    "\n",
    "            variant_df = points_df[\n",
    "                ['Chromosome', 'hg38_start', 'ref_allele', 'alt_allele']\n",
    "            ][\n",
    "                compare(points_df.points, threshold)\n",
    "            ]\n",
    "\n",
    "            if variant_df.empty:\n",
    "                continue\n",
    "\n",
    "            exposure_df, af_map, clinvar_df = hailtools.get_exposure_package(\n",
    "                variant_df,\n",
    "                wgs_mt,\n",
    "                clinvar_bins_df,\n",
    "                contig_col='Chromosome',\n",
    "                pos_col='hg38_start',\n",
    "                ref_col='ref_allele',\n",
    "                alt_col='alt_allele',\n",
    "                metadata_dict={\n",
    "                    'Dataset': 'Combined points',\n",
    "                    'Gene': gene,\n",
    "                    'Classifier': classifier,\n",
    "                    'Classification': classification,\n",
    "                    'Data Version': DATAFRAME_VERSION\n",
    "                }\n",
    "            )\n",
    "\n",
    "            clinvar_classes_dfs.append(clinvar_df)\n",
    "            joint_af_map.update(af_map)\n",
    "            gene_result_dfs.append(exposure_df)\n",
    "\n",
    "    if clinvar_classes_dfs:\n",
    "        pd.concat(clinvar_classes_dfs, ignore_index=True).to_parquet(clinvar_file)\n",
    "    if joint_af_map:\n",
    "        pd.Series(joint_af_map).to_frame(name='AF').to_parquet(af_file)\n",
    "    if gene_result_dfs:\n",
    "        pd.concat(gene_result_dfs, ignore_index=True).to_parquet(exposures_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
